#pragma once
constexpr int MAX_SPLITK_FACTOR = 2;
constexpr int batch_size = 128;
constexpr int hidden_dim = 7168;
constexpr int dq = 1536;
constexpr int seq_len = 1;
constexpr int n_heads = 128;
constexpr int q_lora_dim = dq, kv_lora_dim = 512;
constexpr int nope_dim = 128, rope_dim = 64;
constexpr int v_dim = 128;
constexpr int max_seq_len = 8192;

struct InputParams {
  int prefill;
  int seed;
  void *Q_proj_down_weight;
  void *KV_proj_down_weight;
  void *Q_proj_up_weight;
  void *KV_proj_up_weight;
  void *wo_weight;
};

struct MLAInputRaw {
  InputParams params;
  void *Q_proj_down_weight;
  void *KV_proj_down_weight;
  void *Q_proj_up_weight;
  void *KV_proj_up_weight;
  void *wo_weight;
  void *x;
  void *output_ref;
  void *output;
  void *kv_cache_input;
  void *prefilled_cache;
  void *kv_cache_step0;
  void *kv_cache_step0_ref;
  void *kv_lora;
  void *kv_lora_ref;
  void *k_rope;
  void *k_rope_ref;
  void *q_lora;
  void *q_lora_ref;
  void *qup_nope;
  void *qup_nope_ref;
  void *qup_rope;
  void *qup_rope_ref;
  void *kup_nope;
  void *kup_nope_ref;
  void *vup;
  void *vup_ref;
  void *q_rope_step2;
  void *q_rope_step2_ref;
  void *q_nope;
  void *q_nope_ref;
  void *q_absorb;
  void *q_absorb_ref;
  void *q_rope_permuted;
  void *q_rope_permuted_ref;
  void *q_absorb_permuted;
  void *q_absorb_permuted_ref;
  void *theta;
  void *theta_ref;
  void *q_rope_final;
  void *q_rope_final_ref;
  void *k_rope_final;
  void *k_rope_final_ref;
  void *attn_nope;
  void *attn_nope_ref;
  void *attn_rope;
  void *attn_rope_ref;
  void *scores;
  void *scores_ref;
  void *attention;
  void *attention_ref;
  void *o_step4_0;
  void *o_step4_0_ref;
  void *o_step4_1;
  void *o_step4_1_ref;
};